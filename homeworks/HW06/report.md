# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: 12000, 30
- Целевая переменная: `target` (бинарная: 0 - 67.7%, 1 - 32.3%)
- Признаки: 24 числовых признака (num01-num24), 3 категориальных (cat_contract, cat_region, cat_payment), 1 числовой (tenure_months)

## 2. Protocol

- Разбиение: train/test (80%/20%, `random_state=42`, стратификация по target)
  - Train size: 9600 samples
  - Test size: 2400 samples
  - Распределение классов сохранилось: train (0: 67.66%, 1: 32.34%), test (0: 67.67%, 1: 32.33%)
- Подбор: CV на train (5 фолдов, оптимизация ROC-AUC)
- Метрики: accuracy, F1, ROC-AUC. Выбраны потому что:
  - **Accuracy**: базовая метрика для общего понимания качества
  - **F1-score**: критически важна при дисбалансе классов (32.3% класса 1), балансирует precision и recall
  - **ROC-AUC**: показывает качество разделения классов независимо от порога, устойчива к дисбалансу


## 3. Models

Сравнивались следующие модели:

1. **DummyClassifier (baseline)** - стратегия 'most_frequent' (предсказывает всегда класс 0)
2. **LogisticRegression (baseline из S05)** - с StandardScaler в пайплайне и class_weight='balanced'
3. **DecisionTreeClassifier** - подбирались гиперпараметры для контроля сложности:
   - `max_depth`: [3, 5, 7, 10, None]
   - `min_samples_leaf`: [1, 2, 5, 10]
   - `criterion`: ['gini', 'entropy']
   - **Лучшие параметры**: `{'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 10}`
4. **RandomForestClassifier** - подбирались:
   - `n_estimators`: [100, 200]
   - `max_depth`: [5, 10, None]
   - `min_samples_leaf`: [1, 2, 5]
   - `max_features`: ['sqrt', 'log2']
   - **Лучшие параметры**: `{'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 200}`
5. **GradientBoostingClassifier** - подбирались:
   - `n_estimators`: [100, 200]
   - `learning_rate`: [0.01, 0.1, 0.2]
   - `max_depth`: [3, 5, 7]
   - **Лучшие параметры**: `{'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200}`

**Все модели использовали `class_weight='balanced'` (кроме GradientBoosting, который имеет встроенные механизмы) для учета дисбаланса классов.**

## 4. Results

**Лучшие ROC-AUC на кросс-валидации (train, 5-fold CV):**

| Модель | Лучший ROC-AUC (CV) | Улучшение vs LogisticRegression |
|--------|---------------------|---------------------------------|
| DecisionTree | 0.9086 | +3.3% |
| RandomForest | 0.9690 | +9.4% |
| GradientBoosting | **0.9734** | **+9.8%** |

**Финальные метрики на test:**

| Модель | Accuracy | F1-score | ROC-AUC | Улучшение ROC-AUC vs Dummy |
|--------|----------|----------|---------|----------------------------|
| Dummy | 0.6767 | 0.0000 | 0.5000 | 0% |
| LogisticRegression | 0.8271 | 0.7071 | 0.8752 | +75.0% |
| DecisionTree | 0.8763 | 0.7995 | 0.9080 | +81.6% |
| RandomForest | 0.9263 | 0.8798 | 0.9665 | +93.3% |
| GradientBoosting | **0.9346** | **0.8960** | **0.9709** | **+94.2%** |

**Победитель: GradientBoostingClassifier**

**Краткое объяснение:**
1. **GradientBoosting** показал наивысший ROC-AUC на тесте (0.9709) и кросс-валидации (0.9734)
2. Все метрики последовательно улучшаются от простых к сложным моделям:
   - Accuracy: 67.7% → 82.7% → 87.6% → 92.6% → **93.5%**
   - F1-score: 0.000 → 0.707 → 0.799 → 0.880 → **0.896**
   - ROC-AUC: 0.500 → 0.875 → 0.908 → 0.967 → **0.971**
3. **RandomForest** показал очень близкий результат (ROC-AUC 0.9665), всего на 0.44% хуже
4. Разрыв между DecisionTree и ансамблевыми методами значительный (~6% ROC-AUC)

## 5. Analysis

**Устойчивость**: 
- GradientBoosting демонстрирует высокую устойчивость: разница между CV-score (0.9734) и test-score (0.9709) всего 0.25%
- RandomForest также устойчив: 0.9690 (CV) → 0.9665 (test), разница 0.25%
- DecisionTree менее устойчив: 0.9086 (CV) → 0.9080 (test), но все равно хорошая согласованность

**Ошибки**: Confusion matrix для GradientBoosting показывает:
- Высокая точность предсказаний для обоих классов
- Сбалансированные precision и recall (F1=0.896)
- Минимальное количество ошибок при дисбалансе классов

**Интерпретация (permutation importance):**
**Top-5 наиболее важных признаков для GradientBoosting:**

1. **num19** (importance: 0.1047) - самый важный признак
2. **num18** (importance: 0.1009) - второй по важности
3. **num07** (importance: 0.0608)
4. **num04** (importance: 0.0271)
5. **num24** (importance: 0.0228)

**Наблюдения:**
- Числовые признаки доминируют в важности
- Категориальные признаки не вошли в top-15
- Признаки num19 и num18 имеют значительно более высокую важность, чем остальные

**Влияние гиперпараметров:**
1. **GradientBoosting**: высокая скорость обучения (learning_rate=0.2) с глубокими деревьями (max_depth=7) дала лучший результат
2. **RandomForest**: максимальная глубина деревьев (None) с большим количеством estimators (200) оптимальна
3. **DecisionTree**: потребовалось ограничение сложности (max_depth=10, min_samples_leaf=10)

## 6. Conclusion

1. **Boosting показал наилучшее качество**: GradientBoosting (ROC-AUC 0.9709) немного превзошел RandomForest (0.9665), подтверждая эффективность последовательного улучшения моделей.

2. **Ансамбли радикально лучше одиночных моделей**: 
   - Разрыв между DecisionTree и ансамблевыми методами ~6% ROC-AUC
   - Ансамбли уменьшают variance и улучшают обобщающую способность

3. **Контроль переобучения достигается разными способами**:
   - DecisionTree: явные ограничения (max_depth, min_samples_leaf)
   - RandomForest: bagging + случайный выбор признаков
   - GradientBoosting: последовательное обучение с shrinkage (learning_rate)

4. **Честный ML-протокол успешно применен**:
   - Фиксированный train/test split со стратификацией
   - Подбор гиперпараметров только на train через CV
   - Однократная финальная оценка на test
   - Сохранение всех артефактов эксперимента

5. **Метрики адекватно отражают качество**:
   - ROC-AUC лучше всего показывает качество разделения классов
   - F1-score важна при дисбалансе классов
   - Все метрики согласованно улучшаются от простых к сложным моделям

6. **Интерпретация модели дает insights**:
   - Признаки num19 и num18 наиболее важны для предсказания
   - Модель полагается преимущественно на числовые признаки
   - Permutation importance помогает валидировать модель

**Рекомендация для production**: GradientBoostingClassifier с параметрами `{'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200}` является оптимальным выбором для данной задачи, обеспечивая наивысшее качество предсказаний при сохранении интерпретируемости и устойчивости.