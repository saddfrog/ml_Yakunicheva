# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4:

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000 строк, 8 признаков + sample_id)
- Признаки: все числовые (f01-f08)
- Пропуски: нет пропусков
- "Подлости" датасета: 
  - Признаки в разных шкалах (диапазоны от -215 до +213)
  - Большой разброс значений между признаками
  - Без масштабирования кластеризация невозможна

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000 строк, 3 признака + sample_id)
- Признаки: все числовые (x1, x2, z_noise)
- Пропуски: нет пропусков
- "Подлости" датасета:
  - Нелинейная структура кластеров
  - Наличие шумового признака z_noise с большим разбросом
  - KMeans плохо справляется из-за формы кластеров

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000 строк, 4 признака + sample_id)
- Признаки: все числовые (x1, x2, f_corr, f_noise)
- Пропуски: нет пропусков
- "Подлости" датасета:
  - Кластеры разной плотности
  - Наличие фонового шума
  - Признак f_corr сильно коррелирован с x1, x2
  - Требуется аккуратный подбор параметров для DBSCAN

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг:
  1. Удаление sample_id (не является признаком)
  2. StandardScaler для всех числовых признаков
  3. Пропусков нет, категориальных признаков нет
  4. Использование Pipeline для единообразия обработки

- Поиск гиперпараметров:
  - **KMeans**: k в диапазоне 2-15, выбор по максимуму silhouette score
  - **DBSCAN**: eps = [0.3, 0.5, 0.7, 1.0, 1.5, 2.0], min_samples = [3, 5, 7, 10], выбор по silhouette
  - **Agglomerative**: k как у лучшего KMeans, linkage = ['ward', 'complete', 'average', 'single'], выбор по silhouette
  - Критерий выбора "лучшего": максимизация silhouette score при разумном числе кластеров

- Метрики: 
  - silhouette_score (выше → лучше)
  - davies_bouldin_score (ниже → лучше)
  - calinski_harabasz_score (выше → лучше)
  - Для DBSCAN: шум (-1) исключается при вычислении метрик, доля шума указывается отдельно

- Визуализация: 
  - PCA(2D) для всех датасетов и лучших решений
  - t-SNE не использовался (по условию опционально)
  - Дополнительные графики: silhouette vs k, k-distance plot для DBSCAN

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

**Dataset 01:**
- KMeans: поиск k (2-15), random_state=42, n_init=10
- DBSCAN: поиск eps (0.3-2.0), min_samples (3-10)

**Dataset 02:**
- KMeans: поиск k (2-15), random_state=42, n_init=10
- AgglomerativeClustering: поиск linkage ['ward', 'complete', 'average', 'single'], k=2 (из KMeans)

**Dataset 03:**
- KMeans: поиск k (2-15), random_state=42, n_init=10
- DBSCAN: поиск eps (0.8-2.0), min_samples (3-7) с использованием k-distance plot

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans, k=2, random_state=42
- Метрики: silhouette=0.522, DB=0.685, CH=11786.955
- Если был DBSCAN: доля шума 0% (шума не обнаружено)
- Коротко: KMeans показал отличные результаты на масштабированных данных. Два четких кластера хорошо разделяются. DBSCAN дал аналогичный результат, но KMeans проще интерпретировать.

### 4.2 Dataset B

- Лучший метод и параметры: AgglomerativeClustering, k=2, linkage='single'
- Метрики: silhouette=0.521, DB=0.342, CH=7.184
- Коротко: Agglomerative с single linkage значительно превзошел KMeans (0.521 vs 0.307 silhouette), что ожидаемо для нелинейных кластеров. Single linkage лучше справляется с произвольными формами.

### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN, eps=0.8, min_samples=3
- Метрики: silhouette=0.373, DB=0.551, CH=17.197
- Если был DBSCAN: доля шума 0.15% (22 точки из 15000)
- Коротко: DBSCAN показал лучшее качество чем KMeans (0.373 vs 0.316 silhouette) и корректно выделил небольшое количество шума. Это ожидаемо для кластеров разной плотности.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- **Где KMeans "ломается" и почему?**
  - Dataset 02: silhouette всего 0.307 из-за нелинейной формы кластеров. KMeans предполагает сферические кластеры.
  - Dataset 03: неоптимально из-за разной плотности кластеров.

- **Где DBSCAN/иерархическая кластеризация выигрывают и почему?**
  - Dataset 02: Agglomerative с single linkage выигрывает (0.521 silhouette) благодаря способности находить произвольные формы.
  - Dataset 03: DBSCAN выигрывает (0.373 silhouette) из-за адаптации к разной плотности и выделения шума.

- **Что сильнее всего влияло на результат?**
  1. Масштабирование: критично для всех distance-based методов
  2. Форма кластеров: KMeans проигрывает на нелинейных структурах
  3. Плотность: DBSCAN лучше на кластерах разной плотности
  4. Шумовые признаки: ухудшают качество, если их не обработать

### 5.2 Устойчивость (обязательно для одного датасета)

- **Какую проверку устойчивости делали:** 5 запусков KMeans на Dataset 01 с разными random_state (0, 100, 200, 300, 400)
- **Что получилось:** Средний ARI = 1.000, стандартное отклонение = 0.000. Все запуски дали идентичные разбиения.
- **Вывод:** Кластеризация абсолютно устойчива для Dataset 01. Это объясняется четким разделением данных на два кластера и большим расстоянием между ними.

### 5.3 Интерпретация кластеров

- **Как вы интерпретировали кластеры:**
  - Анализ средних значений признаков в каждом кластере
  - Визуализация в PCA пространстве
  - Для Dataset 01: кластер 0 имеет положительные значения f02, отрицательные f04; кластер 1 - наоборот
  - Для Dataset 02: кластеры соответствуют двум "дугам" в пространстве (x1, x2)
  - Для Dataset 03: DBSCAN выделил плотные области и небольшой шум

- **Выводы:**
  1. Dataset 01 имеет два четко разделенных кластера с противоположными паттернами значений
  2. Dataset 02 содержит два нелинейных кластера, хорошо разделяемых иерархическим методом
  3. Dataset 03 содержит кластеры разной плотности и немного шума
  4. PCA визуализация хорошо соответствует содержательной интерпретации

## 6. Conclusion

1. **Масштабирование обязательно:** Без StandardScaler результаты KMeans и DBSCAN бессмысленны на данных с разными шкалами.

2. **Выбор метода зависит от структуры данных:** 
   - KMeans хорош для сферических кластеров схожей плотности
   - DBSCAN лучше для кластеров произвольной формы и разной плотности
   - Agglomerative с single linkage эффективен для нелинейных структур

3. **Метрики качества:** Silhouette score наиболее информативен для подбора числа кластеров. Davies-Bouldin индекс хорошо коррелирует с визуальной оценкой.

4. **Устойчивость важна:** KMeans может быть неустойчив на сложных данных, но на четко разделенных кластерах дает стабильные результаты.

5. **Визуализация обязательна:** PCA помогает понять структуру данных и оценить качество кластеризации.

6. **DBSCAN требует аккуратной настройки:** k-distance plot помогает выбрать параметр eps, но автоматический подбор сложен.

7. **Интерпретация результатов:** Анализ профилей кластеров по средним значениям признаков помогает понять природу выделенных групп.

8. **"Честный" протокол:** Использование одного препроцессинга для всех моделей, разделение данных на признаки и идентификаторы, сохранение всех артефактов эксперимента.